{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnlzer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "source_path = 'test_data'\n",
    "#source_file = 'test_strains_reviews.csv'\n",
    "target_path = '/Users/jordanweil/green_rex/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"reviews = pd.read_csv('test_data/test_strains_reviews.csv')\\nr = reviews.set_index('Unnamed: 0')\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"reviews = pd.read_csv('test_data/test_strains_reviews.csv')\n",
    "r = reviews.set_index('Unnamed: 0')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews2(l):\n",
    "    \"\"\"Pass in a list of URL's and return them in a mongo db table as a dicitonary with \n",
    "    {'url', 'html'} and their corresponding values\"\"\"\n",
    "    r = requests.get(l)\n",
    "    html = (r.content)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stars_list(d):\n",
    "#     stars = []\n",
    "#     for key, values in d.items():\n",
    "#         soup = BeautifulSoup(values, 'html.parser')\n",
    "#         tags = soup.select(\"div.div.stars\")\n",
    "#         for t in tags:\n",
    "#             stars.append(t.attrs['style'])\n",
    "#     return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_int_conv(s):\n",
    "    star = (int((s[6:].split(';')[0]).strip('px'))/22)\n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_strains(i):\n",
    "    LOS = []\n",
    "    Type = []\n",
    "    r = requests.get(i)\n",
    "    soup2 = BeautifulSoup(r.content, 'html.parser')\n",
    "    strains = soup2.find_all('a', class_=\"ga_Explore_Strain_Tile\")\n",
    "    for s in strains:\n",
    "        LOS.append(str(s.attrs['href'])[8:])\n",
    "        Type.append(str(s.attrs['href'])[1:7])\n",
    "    z = list(zip(LOS,Type))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_dict_entry(strain, stype, user_id, userstars, userreview, straindict):\n",
    "    if straindict is None:\n",
    "        straindict = {}\n",
    "        \n",
    "    if strain not in straindict:\n",
    "        straindict[strain] = {\n",
    "            \"stype\" : stype,\n",
    "            \"user_rev\" : [] \n",
    "        }\n",
    "        \n",
    "    straindict[strain]['user_rev'].append({'user':user_id,\n",
    "                                         'stars':userstars,\n",
    "                                         'review':userreview\n",
    "                                        })\n",
    "    return straindict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs2(d):\n",
    "    \"\"\"Parse the HTML docs that we have stored in a dictionary, return as a list.\n",
    "    Also scrape and parse star rating for each review \"\"\"\n",
    "    strain_text= []\n",
    "    star_rate = []\n",
    "    user_name = []\n",
    "    \n",
    "    soup = BeautifulSoup(d, 'html.parser')\n",
    "    revs = soup.find_all('p',class_='strain-review__text') \n",
    "    for r in revs:\n",
    "        text = r.text\n",
    "        remove_punch = re.sub('[^A-Za-z ]' , \"\" ,text )\n",
    "        token = remove_punch.lower().split()\n",
    "        srm_token = [wnlzer.lemmatize(i) for i in token if not i in set(stopwords.words('english'))]\n",
    "        clean_text = \" \".join(srm_token)\n",
    "        strain_text.append(clean_text)\n",
    "        \n",
    "    tags = soup.select(\"div.div.stars\")\n",
    "    for t in tags:\n",
    "        star = t.attrs['style']\n",
    "        star_rate.append(star_int_conv(star))\n",
    "    \n",
    "    users = soup.find_all('div', class_='strain-review__title')\n",
    "    for u in users:\n",
    "        temp = u.find('h2')\n",
    "        user_name.append(temp.text)\n",
    "        \n",
    "    return star_rate, strain_text, user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy1(los):\n",
    "    \"\"\"pass in a list of strains to be scraped from Leafly.\n",
    "    returns dictionary keyed by strains w/strain info(reviews) as values\"\"\"\n",
    "    cnt = 0\n",
    "    strain_dict = None\n",
    "    for s in los:\n",
    "        strain = s[0]\n",
    "        stype = s[1]\n",
    "        url = \"https://www.leafly.com/{}/{}/reviews?page=\".format(stype, strain)\n",
    "    \n",
    "        for i in range(1,100):\n",
    "            rev_url=url+str(i)\n",
    "            d = get_reviews2(rev_url)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            #print(star)\n",
    "            if len(star) == 0:\n",
    "                break\n",
    "\n",
    "            for userstars, userreview ,user_id in zip(star, reviews, users):\n",
    "                strain_dict = strain_dict_entry(strain, stype, user_id, userstars, userreview, strain_dict)\n",
    "                \n",
    "            \n",
    "            if cnt % 10 == 0:\n",
    "                print(cnt)\n",
    "            cnt +=1\n",
    "            \n",
    "    return strain_dict         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strains = list_o_strains('https://www.leafly.com/explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue-dream', 'hybrid'),\n",
       " ('sour-diesel', 'sativa'),\n",
       " ('gsc', 'hybrid'),\n",
       " ('green-crack', 'sativa'),\n",
       " ('og-kush', 'hybrid'),\n",
       " ('granddaddy-purple', 'indica'),\n",
       " ('original-glue', 'hybrid'),\n",
       " ('white-widow', 'hybrid'),\n",
       " ('blue-dream', 'hybrid'),\n",
       " ('sour-diesel', 'sativa'),\n",
       " ('gsc', 'hybrid'),\n",
       " ('green-crack', 'sativa'),\n",
       " ('og-kush', 'hybrid'),\n",
       " ('granddaddy-purple', 'indica'),\n",
       " ('original-glue', 'hybrid'),\n",
       " ('white-widow', 'hybrid'),\n",
       " ('jack-herer', 'sativa'),\n",
       " ('bubba-kush', 'indica'),\n",
       " ('pineapple-express', 'hybrid'),\n",
       " ('trainwreck', 'hybrid'),\n",
       " ('ak-47', 'hybrid'),\n",
       " ('durban-poison', 'sativa'),\n",
       " ('northern-lights', 'indica'),\n",
       " ('headband', 'hybrid'),\n",
       " ('blue-cheese', 'indica'),\n",
       " ('strawberry-cough', 'sativa'),\n",
       " ('chemdawg', 'hybrid'),\n",
       " ('purple-kush', 'indica'),\n",
       " ('lemon-haze', 'sativa'),\n",
       " ('super-lemon-haze', 'sativa'),\n",
       " ('grape-ape', 'indica'),\n",
       " ('blueberry', 'indica'),\n",
       " ('alaskan-thunder-fuck', 'sativa'),\n",
       " ('super-silver-haze', 'sativa'),\n",
       " ('blackberry-kush', 'indica'),\n",
       " ('cherry-pie', 'hybrid'),\n",
       " ('master-kush', 'indica'),\n",
       " ('skywalker-og', 'hybrid'),\n",
       " ('cheese', 'hybrid'),\n",
       " ('death-star', 'indica'),\n",
       " ('chocolope', 'sativa'),\n",
       " ('amnesia-haze', 'sativa'),\n",
       " ('tahoe-og', 'hybrid'),\n",
       " ('maui-wowie', 'sativa'),\n",
       " ('platinum-gsc', 'hybrid'),\n",
       " ('harlequin', 'sativa'),\n",
       " ('gods-gift', 'indica'),\n",
       " ('la-confidential', 'indica'),\n",
       " ('agent-orange', 'hybrid'),\n",
       " ('purple-urkle', 'indica'),\n",
       " ('lemon-kush', 'hybrid'),\n",
       " ('mazar-x-blueberry', 'hybrid'),\n",
       " ('golden-goat', 'hybrid'),\n",
       " ('afghan-kush', 'indica'),\n",
       " ('dutch-treat', 'hybrid'),\n",
       " ('hindu-kush', 'indica')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Only needs to be ran once\\nd = scraper_dummy1(test_strains)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Only needs to be ran once\n",
    "d = scraper_dummy1(test_strains)\"\"\"\n",
    "\n",
    "#Already ran it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6b9b4f16b922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_rev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "for k in d.keys():\n",
    "    print(k,len(d[k]['user_rev']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-420d29d2d160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gsc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_rev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "d['gsc']['user_rev'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files(d):\n",
    "    cnt = 0\n",
    "    for strain in d.keys():\n",
    "\n",
    "        if not os.path.isdir(os.path.join(target_path, strain)):\n",
    "             os.mkdir(os.path.join(target_path, strain))\n",
    "\n",
    "        for rev in d[strain]['user_rev']:\n",
    "\n",
    "            with open(os.path.join(target_path, strain, strain+'{:05d}.txt'.format(cnt)), mode='w') as strain_file:\n",
    "                strain_file.write(rev['review'])\n",
    "\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_files(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ = \"a,able,about,across,after,all,almost,also,am,among,an,and,any,\\\n",
    "are,as,at,be,because,been,but,by,can,could,dear,did,do,does,either,\\\n",
    "else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,\\\n",
    "how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,\\\n",
    "me,might,most,must,my,neither,no,of,off,often,on,only,or,other,our,\\\n",
    "own,rather,said,say,says,she,should,since,so,some,than,that,the,their,\\\n",
    "them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,\\\n",
    "what,when,where,which,while,who,whom,why,will,with,would,yet,you,your]\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['your'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "    dataset = load_files(target_path, shuffle=False)\n",
    "    print('n_samples {}'.format(len(dataset.data)))\n",
    "\n",
    "    # split the dataset in training and test set:\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.15, random_state=None)\n",
    "\n",
    "    \n",
    "    \n",
    "    # #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (5,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data.data, data.target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "    # that are too rare or too frequent\n",
    "    clf = Pipeline([\n",
    "        ('vect',TfidfVectorizer(analyzer='character', stop_words=stopwords_)),\n",
    "        ('clf', Perceptron())\n",
    "    ])\n",
    "\n",
    "    # TfidfVectorizer().get_params()\n",
    "    # TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "    # more useful.\n",
    "    # Fit the pipeline on the training set using grid search for the parameters\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 5), (1,10),(1,20)],\n",
    "        'vect__analyzer': ['word']#,'char']\n",
    "    }\n",
    "    \n",
    "    \n",
    "    gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "    cclf = gs_clf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vect__analyzer': 'word', 'vect__ngram_range': (1, 5)}\n",
      "0.5577777777777778\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "  .ipynb_checkpoints       0.00      0.00      0.00         0\n",
      "         afghan-kush       0.00      0.00      0.00         6\n",
      "        agent-orange       0.24      0.31      0.27        13\n",
      "               ak-47       0.38      0.22      0.28        23\n",
      "alaskan-thunder-fuck       0.22      0.14      0.17        14\n",
      "        amnesia-haze       0.41      0.33      0.37        27\n",
      "     blackberry-kush       0.29      0.12      0.17        17\n",
      "         blue-cheese       0.83      0.29      0.43        17\n",
      "          blue-dream       0.76      0.84      0.80       135\n",
      "           blueberry       0.50      0.37      0.42        19\n",
      "          bubba-kush       0.60      0.22      0.32        41\n",
      "              cheese       0.07      0.20      0.11         5\n",
      "            chemdawg       0.25      0.18      0.21        17\n",
      "          cherry-pie       0.19      0.33      0.24        12\n",
      "           chocolope       0.09      1.00      0.17         1\n",
      "          death-star       0.00      0.00      0.00        13\n",
      "       durban-poison       0.29      0.28      0.29        32\n",
      "         dutch-treat       0.25      0.14      0.18         7\n",
      "           gods-gift       0.29      0.20      0.24        10\n",
      "         golden-goat       0.20      0.25      0.22         8\n",
      "   granddaddy-purple       0.76      0.89      0.82        76\n",
      "           grape-ape       0.29      0.18      0.22        22\n",
      "         green-crack       0.86      0.88      0.87        67\n",
      "                 gsc       0.85      0.91      0.88        77\n",
      "           harlequin       0.55      0.41      0.47        29\n",
      "            headband       0.78      0.37      0.50        19\n",
      "          hindu-kush       0.00      0.00      0.00        11\n",
      "          jack-herer       0.26      0.41      0.32        17\n",
      "     la-confidential       0.20      0.07      0.10        15\n",
      "          lemon-haze       0.00      0.00      0.00        11\n",
      "          lemon-kush       0.10      0.29      0.15         7\n",
      "         master-kush       0.05      0.12      0.07         8\n",
      "          maui-wowie       0.29      0.24      0.26        17\n",
      "   mazar-x-blueberry       0.00      0.00      0.00         4\n",
      "     northern-lights       0.26      0.17      0.21        29\n",
      "             og-kush       0.81      0.75      0.78        64\n",
      "       original-glue       0.89      0.92      0.90        59\n",
      "   pineapple-express       0.37      0.38      0.38        52\n",
      "        platinum-gsc       0.00      0.00      0.00         6\n",
      "         purple-kush       1.00      0.22      0.36        18\n",
      "        purple-urkle       0.29      0.35      0.32        17\n",
      "        skywalker-og       0.00      0.00      0.00         5\n",
      "         sour-diesel       0.80      0.83      0.81       161\n",
      "    strawberry-cough       0.53      0.45      0.49        20\n",
      "    super-lemon-haze       0.64      0.23      0.33        31\n",
      "   super-silver-haze       0.22      0.12      0.16        16\n",
      "            tahoe-og       0.25      0.11      0.15         9\n",
      "          trainwreck       0.13      0.25      0.17         8\n",
      "         white-widow       0.74      0.83      0.78        58\n",
      "\n",
      "           micro avg       0.56      0.56      0.56      1350\n",
      "           macro avg       0.36      0.32      0.31      1350\n",
      "        weighted avg       0.59      0.56      0.56      1350\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE7tJREFUeJzt3W+oZdV5x/Hf4/xziBNG42gHRzoWjOiLROFiLfZFMQm1JkRf2JIQy7wYmLxIQNNAohZsDSXVN9FCS5shSiYYoqkJKCIUmSihULQ30aSaQceIbcXBueIMGYOMc/Xpi7NdvWefdeesWXfttfeefD9wmbv37LPXc/Y995m1n1lrbXN3AYAkndF3AACGg4QAICAhAAhICAACEgKAgIQAIKieEMzsWjN70cxeNrNba7efwszuN7PDZvb8in3nmNkTZnaw+fPsPmOMMbMLzexJMztgZi+Y2c3N/sHGbmZnmtkzZvaLJuY7m/0XmdnTTcwPmdnGvmNtM7N1ZvasmT3WbA8+5nmqJgQzWyfpnyT9maTLJH3ezC6rGUOi70q6trXvVkn73f1iSfub7aFZlvRVd79U0lWSvtRc3yHHflzSNe7+cUmXS7rWzK6SdLeke5qYj0ja3WOMq7lZ0oEV22OI+aRq9xCulPSyu7/i7u9KelDS9ZVjmMvdfyrprdbu6yXta77fJ+mGqkElcPdD7v7z5vtjmnxYL9CAY/eJt5vNDc2XS7pG0sPN/kHFLElmtkPSpyV9p9k2DTzmFLUTwgWS/nfF9mvNvjE4390PSZNfPEnn9RzPSZnZTklXSHpaA4+96Xo/J+mwpCck/VrSUXdfbg4Z4ufkXklfk/R+s/0RDT/muWonBIvsY+x0YWZ2lqQfSbrF3X/TdzzzuPt77n65pB2a9CIvjR1WN6rVmdlnJB1295+t3B05dDAxp1pfub3XJF24YnuHpNcrx5DrDTPb7u6HzGy7Jv+aDY6ZbdAkGXzf3X/c7B5F7O5+1Mye0qT+sdXM1jf/4g7tc3K1pM+a2XWSzpT0YU16DEOOOUntHsJ/Srq4qcZulPQ5SY9WjiHXo5J2Nd/vkvRIj7FENfex90k64O7fWvFXg43dzLaZ2dbm+82SPqlJ7eNJSTc2hw0qZne/zd13uPtOTT7DP3H3L2jAMSdz96pfkq6T9JIm94l/Xbv9xBh/IOmQpBOa9Gp2a3KPuF/SwebPc/qOMxL3H2vSTf2lpOear+uGHLukj0l6ton5eUl3NPv/QNIzkl6W9K+SNvUd6yrx/4mkx8YU88m+rHkjAMBIRQD/j4QAICAhAAhICAACEgKAoJeEYGZ7+mh3rcYY9xhjlsYZ9xhjbltTQljDVOaxXrgxxj3GmKVxxj3GmKdkJ4QRTWUGkCh7YJKZ/ZGkv3X3P222b5Mkd//7VV9z7rmunTulpSVp27asdns1xrjHGLM0zriHHPOrr8rffDM2AWvKWiY3xaYy/+FJX7Fzp7S4uIYmAWRZWEg6bC01hKTpnma2x8wWzWxRS0traA5A19aSEJKmMrv7XndfcPeFwXanAEhaW0IY81Tm4synv0qdJ/VcpdovJfd91D730K5b37JrCO6+bGZflvRvktZJut/dXygWGYDq1rRikrs/LunxQrEA6BlDlwEEtddUnLlP89b/VWw6Pvua45tOfo7YeUrFU1JK3Lntdxn3uvemt99bN/81XcZT8tztc5X8bKWo+flLQQ8BQEBCABCQEAAEJAQAQfWi4ryiybuR5+Vufmd6+53Ns8dsODG9fWJDWjxnvD+9/X4kRaYUetrnSSm8jUXN99IuYNZuP1dKcTClYFmqqDlTCE58HT0EAAEJAUBAQgAQVK8hzBO7X2rXDGL3mcutd5J6L1bq/jRWe0hpvx1nuxYhpcXY5QCXnHPn3gunXMcudTkwLPeYnOufex3pIQAISAgAAhICgICEACAY3GzHlGJUrMh29pHp7SNnz287psuCWcqgm9xiUJezPWvOpIzpcmBSqWJsqYFJMTVnQNJDABCQEAAEJAQAweAGJq1fnt2XMlGpXTNInSSTUlfIuc/MnaRT6n4xdQXhvlfoaddMunz/tesjXbXV5cpb9BAABCQEAAEJAUBAQgAQDG7FpNSVjtrahZZYAa+98pI0u0JT7HXtmFMKhiUH0+QUNfsuFqbKibPLotoYVmzKGTyX+pQ6eggAAhICgICEACAgIQAIqhYVzaWNrWc3tp/bmCul0BJbvv3FS6a3L3lx/nlSikypxamU5ybWLBDWLqqlvP+cGZG5Mwtzf0ZDW4afkYoA1oyEACAgIQAIqtYQ3OKPalup1KOsUl32q+ntLcdmjzm2ZXo7d1WnmL6XHW9LmRFaalWh1dpry5kRWfIzkxNjTO3Pdo6BfRwB9ImEACAgIQAI5iYEM7vfzA6b2fMr9p1jZk+Y2cHmz8gaxwDGJqWo+F1J/yjpeyv23Sppv7vfZWa3NttfT2lw3gCOvoss7QKilLfEe+r7iD3LsS1l0E3bxndn98UKujnL4MekDN6JSblu7WX1UmbEllxCrtRS9SWLsW3zPkcJY7sm55l3gLv/VNJbrd3XS9rXfL9P0g2J7QEYsNwawvnufkiSmj/PKxcSgL50XlQ0sz1mtmhmi1pa6ro5AGuQOzDpDTPb7u6HzGy7pMOrHejueyXtlSRbWPB595a1B2+k3Ou2awap96el2m9LuR65k8Zyr3XuZJ6U9nJW0Sp5v953XSul/VLL2ef2EB6VtKv5fpekRzLPA2BAUv7b8QeS/kPSJWb2mpntlnSXpE+Z2UFJn2q2AYzc3FsGd//8Kn/1icKxAOgZIxUBBNWXYZ83yKN2AafUTL6cwTOx9mNyYspd+WgMy5APUcrnaMOJ2X25jx1oK/V7Qw8BQEBCABCQEAAEg3uUW0xX99m5Ym217wU3HZ89JmWwUKn3EVvBJ+U69l0v6HtgUG5bXQ2wqo0eAoCAhAAgICEACEgIAILqRcUcXRaVujp3rIBYs2DW9wy9XGON+3RBDwFAQEIAEJAQAAQkBABB1aKiubSxNYKvXXxLKbz1PZotV80Ya1+jUrNGuzx33zM5+24/BT0EAAEJAUBAQgAQVB+YFJuFt1Ls/rDL+9N5bcXaK3l/3j7X1qOzx+QsA1/yGqU8pq3U+4+dp/2YsthnKKX9lPv1Llc1aq+qJXVXQ5i5romvo4cAICAhAAhICAACEgKAoGpR0U1azmix1LJrpQqWJQt27XO1C4hS3aJqbTWfW5iiy2XOcp+3maP2sx0BnIZICAACEgKAYBTLsHfZTt/34yn1gfa+2pNk+p4A1JYbzxAnFw2tPkQPAUBAQgAQkBAABCQEAEH1omKJIkqXsw1rF3Vy2osVwlJmJPYt5ed2uhRHY1JmqfaNHgKAgIQAICAhAAjm1hDM7EJJ35P0e5Lel7TX3f/BzM6R9JCknZJelfQX7n5k3vlK3KN3OblorNr3x9+4Y/aYO/9m/uu6dLpc65iUGk575afVjuuq/RQpPYRlSV9190slXSXpS2Z2maRbJe1394sl7W+2AYzY3ITg7ofc/efN98ckHZB0gaTrJe1rDtsn6YauggRQxynVEMxsp6QrJD0t6Xx3PyRNkoak81Z5zR4zWzSzRS0trS1aAJ1KTghmdpakH0m6xd1/k/o6d9/r7gvuvqBt23JiBFBJ0sAkM9ugSTL4vrv/uNn9hpltd/dDZrZd0uESAdVeYjyl/S5nG+YUg1Ku0R3fmN236fjsvnZ7pQZ9dbliVUmlPm/zHi+wFinXqFRxcu7bMDOTdJ+kA+7+rRV/9aikXc33uyQ9UiYkAH1J6SFcLekvJf2XmT3X7Ltd0l2SfmhmuyX9j6Q/7yZEALXMTQju/u+SVus0faJsOAD6xEhFAEHV2Y7m0sZWYau9NHXtolJOUa/k6L6cc+Veo9gy4F+5Z3r7nq/knTt3pFzfoxdLtV/q2ZK55y6FHgKAgIQAICAhAAhG8Si3LvW9xHjfq/jce8v09jdvnz3m9m/OP0/7fQzxvWI+eggAAhICgICEACAgIQAIqpf4upwV1pX2bLPcpbBSjokV49rXLGXWYEzKcyNjBcTz35jefuP8+W2l/py7mu1Ycqn+HCk/R6m7mGYGiiW+boS/ngC6QkIAEJAQAATVawhd3TPl3oumTMoZw+PGurw/btcMthybPebYljJt1V6xKqf9lNflxlOq9tHlMuwAfkeQEAAEJAQAAQkBQFC9qNjVQJTc8+QMlCq5VPzQlp1PaSulgJgac1cFs9zr3/cy8F0NzEr4mEmihwBgBRICgICEACCoXkNoTwxKmbiTIvdeLKe9kveZ7XOl1BTGoMvBSyXlDDpKmSRWu/229u8Zk5sAnDISAoCAhAAgICEACHpfMSmlqJZSRCl1nphSg0dSYur70WalxAqIKe+/1ECtUrMWU1/X1Xly28tdmYweAoCAhAAgICEACEgIAIKBPWmx/uzHLkehdXWekroqmKUuQ962fnl234kNaXGdLJ7VDG32bamiei56CAACEgKAYG5CMLMzzewZM/uFmb1gZnc2+y8ys6fN7KCZPWRmG7sPF0CXUnoIxyVd4+4fl3S5pGvN7CpJd0u6x90vlnRE0u6UBt2mv/o2tHhizKe/+ta+ZrHr9t662a+U171/xuxXjvY1W+26teNJfV1XMaVco5Rz55p7uX3i7WZzQ/Plkq6R9HCzf5+kG/LDADAESfnXzNaZ2XOSDkt6QtKvJR119w9qwq9JuqCbEAHUkpQQ3P09d79c0g5JV0q6NHZY7LVmtsfMFs1sUUtL+ZEC6Nwp3aG5+1FJT0m6StJWM/tgHMMOSa+v8pq97r7g7gvatm0tsQLoWMr/Mmwzs63N95slfVLSAUlPSrqxOWyXpEe6CrKmUkWlksWpEkWm2sXI3PZjxcic86QW59rn7rKol3Lu3OtWqjieMlJxu6R9ZrZOkwTyQ3d/zMx+JelBM/s7Sc9Kui8/DABDMDchuPsvJV0R2f+KJvUEAKcJRioCCAY3uSlXqUkqY53ccrq0H9NeUjw2Aer4prxzt+PccGL2mJzJVTGxCV9tKY+p6xI9BAABCQFAQEIAEJAQAASnTVFxqDMVT1Xf76Pv9mPahbYuC2+5BcT2ddt0fPaY3MJnTfQQAAQkBAABCQFAULWGYC6tbw38KDXoI1d7sEjs/jRn0FPsHvLdyCJzOY+gK/VItNjrcuUODOtq1ePN78zue2fz/PZTpMQYqxd0+Zi49uCt3DoLPQQAAQkBQEBCABCQEAAEVYuKbv0XEXPkFGyWI1e21CO5Uo5pxyx1O6Ant6jV1UCoWAHxpgdm9z1w0/R2bEZiqesWe68pRe2U85RCDwFAQEIAEJAQAAQkBADBaTPbsUs5RaW+l8JKfSZiTlErpu/3m6JdQJSkL357evvbX6wTywdKXbdS56GHACAgIQAISAgAgsHNdkwZGJIyQy11YE7OgJpSMxKl2fcbu/cvtQx6LKZ2e7kz6UrNWiw1IzBlyXNptmbw0Zdmj3npo6fefkzue0u5tvN+J1InddJDABCQEAAEJAQAAQkBQDC42Y65s73aRZXUgRo5sy9LzUiUuhvQU3IJtS5n4HW1hFrudS1VQIzp+3mjKeghAAhICAACEgKA4LSZ3JR7n1Vqck9bygCfrtvLeV2XtYBSg476lvKYtto//1LXkR4CgICEACAgIQAIkhOCma0zs2fN7LFm+yIze9rMDprZQ2YWeVAZgDE5laLizZIOSPpws323pHvc/UEz+xdJuyX988lOkPtsx65mBEp5RZ3c4liXqwrlzrbsqv3cY/qWMts29tzGD/12evu3H5p/niFK6iGY2Q5Jn5b0nWbbJF0j6eHmkH2SbugiQAD1pN4y3Cvpa5I++I+Tj0g66u7LzfZrki4oHBuAyuYmBDP7jKTD7v6zlbsjh0b/J9zM9pjZopkt+ptLmWECqCGlhnC1pM+a2XWSztSkhnCvpK1mtr7pJeyQ9Hrsxe6+V9JeSbKFBc+ZTDS0e68x3C/33X5tm9+Z3o49yi1F7mctVjMYo7k9BHe/zd13uPtOSZ+T9BN3/4KkJyXd2By2S9IjnUUJoIq1jEP4uqS/MrOXNakp3FcmJAB9OaW5DO7+lKSnmu9fkXRl+ZAA9IWRigCC6suwb2zNFIsN8qgpZbnunEJTygCXkq8bmtrvv11E3HBi9pjYgLb2udsDjKRyBcOc5dNzzcw+TXwdPQQAAQkBQEBCABCQEAAE1Zdhf3dgk6S7KtjlnjdW+MpR6jmCsdelHJP7PlKeGxnTbn858slOef+xAmKpZeZiS6idfWR6+8jZeeduy46xTPMATgckBAABCQFAUH0Z9px7m5Sl0nPv87p6lFiqdvvrl2ePac8Q7bI+UHsmZzum2H12Tj0iN8bYgKacGboxsZ9tu2aw5djsMW+fNb3d5WeUHgKAgIQAICAhAAhICACC6kXFnCJeu6hUconxrpYvzz1PbEBNiXhSX9f38u0lC8Y5Uq5/rpTi6LEts/u6ev5oDD0EAAEJAUBAQgAQDG5gUu172FJt5d7nptQwumx/Xjy5Sv7MStVwYoOeaq5GldtW+3Vd/o7QQwAQkBAABCQEAAEJAUAwuIFJucWRmoM3Yvouxv0uPcsxd9Zmymei78Jjith7K/X5p4cAICAhAAhICACCwQ1MypV7z9T3ikld1T5yB68M8VFyNetDXZ67y2vbPs9ND0xvP/5W2nnoIQAISAgAAhICgICEACAw944eUB9rzGxJ0n9LOlfSm9UaLmeMcY8xZmmccQ855t93923zDqqaEEKjZovuvlC94TUaY9xjjFkaZ9xjjLmNWwYAAQkBQNBXQtjbU7trNca4xxizNM64xxjzlF5qCACGiVsGAAEJAUBAQgAQkBAABCQEAMH/AeZnaegVYQ9JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = gs_clf.predict(docs_test)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "print(cclf.score(docs_test, y_test))\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "#print(cm)\n",
    "\n",
    "plt.matshow(cm, cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To feel these like (yawn) try smoking purple-urkle\n",
      "To feel these like (smile) try smoking maui-wowie\n",
      "To feel these like (happy) try smoking blue-dream\n",
      "To feel these like (fun) try smoking ak-47\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\n",
    "    u'yawn',\n",
    "    u'smile',\n",
    "    u'happy',\n",
    "    u'fun'\n",
    "]\n",
    "\n",
    "predicted = cclf.predict(test_strings)\n",
    "\n",
    "for s, p in zip(test_strings, predicted):\n",
    "    print(u'To feel these like ({}) try smoking {}'.format(s, dataset.target_names[p]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
