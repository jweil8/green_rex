{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnlzer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "source_path = 'test_data'\n",
    "#source_file = 'test_strains_reviews.csv'\n",
    "target_path = '/Users/jordanweil/green_rex/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"reviews = pd.read_csv('test_data/test_strains_reviews.csv')\\nr = reviews.set_index('Unnamed: 0')\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"reviews = pd.read_csv('test_data/test_strains_reviews.csv')\n",
    "r = reviews.set_index('Unnamed: 0')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews2(l):\n",
    "    \"\"\"Pass in a list of URL's and return them in a mongo db table as a dicitonary with \n",
    "    {'url', 'html'} and their corresponding values\"\"\"\n",
    "    r = requests.get(l)\n",
    "    html = (r.content)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stars_list(d):\n",
    "#     stars = []\n",
    "#     for key, values in d.items():\n",
    "#         soup = BeautifulSoup(values, 'html.parser')\n",
    "#         tags = soup.select(\"div.div.stars\")\n",
    "#         for t in tags:\n",
    "#             stars.append(t.attrs['style'])\n",
    "#     return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_int_conv(s):\n",
    "    star = (int((s[6:].split(';')[0]).strip('px'))/22)\n",
    "    \n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_strains(i):\n",
    "    LOS = []\n",
    "    Type = []\n",
    "    r = requests.get(i)\n",
    "    soup2 = BeautifulSoup(r.content, 'html.parser')\n",
    "    strains = soup2.find_all('a', class_=\"ga_Explore_Strain_Tile\")\n",
    "    for s in strains:\n",
    "        LOS.append(str(s.attrs['href'])[8:])\n",
    "        Type.append(str(s.attrs['href'])[1:7])\n",
    "    z = list(zip(LOS,Type))\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_dict_entry(strain, stype, user_id, userstars, userreview, straindict):\n",
    "    if straindict is None:\n",
    "        straindict = {}\n",
    "        \n",
    "    if strain not in straindict:\n",
    "        straindict[strain] = {\n",
    "            \"stype\" : stype,\n",
    "            \"user_rev\" : [] \n",
    "        }\n",
    "        \n",
    "    straindict[strain]['user_rev'].append({'user':user_id,\n",
    "                                         'stars':userstars,\n",
    "                                         'review':userreview\n",
    "                                        })\n",
    "    return straindict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs2(d):\n",
    "    \"\"\"Parse the HTML docs that we have stored in a dictionary, return as a list.\n",
    "    Also scrape and parse star rating for each review \"\"\"\n",
    "    strain_text= []\n",
    "    star_rate = []\n",
    "    user_name = []\n",
    "    \n",
    "    soup = BeautifulSoup(d, 'html.parser')\n",
    "    revs = soup.find_all('p',class_='strain-review__text') \n",
    "    for r in revs:\n",
    "        text = r.text\n",
    "        remove_punch = re.sub('[^A-Za-z ]' , \"\" ,text )\n",
    "        token = remove_punch.lower().split()\n",
    "        srm_token = [wnlzer.lemmatize(i) for i in token if not i in set(stopwords.words('english'))]\n",
    "        clean_text = \" \".join(srm_token)\n",
    "        strain_text.append(clean_text)\n",
    "        \n",
    "    tags = soup.select(\"div.div.stars\")\n",
    "    for t in tags:\n",
    "        star = t.attrs['style']\n",
    "        star_rate.append(star_int_conv(star))\n",
    "    \n",
    "    users = soup.find_all('div', class_='strain-review__title')\n",
    "    for u in users:\n",
    "        temp = u.find('h2')\n",
    "        user_name.append(temp.text)\n",
    "        \n",
    "    return star_rate, strain_text, user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy1(los):\n",
    "    \"\"\"pass in a list of strains to be scraped from Leafly.\n",
    "    returns dictionary keyed by strains w/strain info(reviews) as values\"\"\"\n",
    "    cnt = 0\n",
    "    strain_dict = None\n",
    "    for s in los:\n",
    "        strain = s[0]\n",
    "        stype = s[1]\n",
    "        url = \"https://www.leafly.com/{}/{}/reviews?page=\".format(stype, strain)\n",
    "    \n",
    "        for i in range(1,100):\n",
    "            rev_url=url+str(i)\n",
    "            d = get_reviews2(rev_url)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            #print(star)\n",
    "            if len(star) == 0:\n",
    "                break\n",
    "\n",
    "            for userstars, userreview ,user_id in zip(star, reviews, users):\n",
    "                strain_dict = strain_dict_entry(strain, stype, user_id, userstars, userreview, strain_dict)\n",
    "                \n",
    "            \n",
    "            if cnt % 10 == 0:\n",
    "                print(cnt)\n",
    "            cnt +=1\n",
    "            \n",
    "    return strain_dict         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strains = list_o_strains('https://www.leafly.com/explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('blue-dream', 'hybrid'),\n",
       " ('sour-diesel', 'sativa'),\n",
       " ('gsc', 'hybrid'),\n",
       " ('green-crack', 'sativa'),\n",
       " ('og-kush', 'hybrid'),\n",
       " ('granddaddy-purple', 'indica'),\n",
       " ('original-glue', 'hybrid'),\n",
       " ('white-widow', 'hybrid'),\n",
       " ('blue-dream', 'hybrid'),\n",
       " ('sour-diesel', 'sativa'),\n",
       " ('gsc', 'hybrid'),\n",
       " ('green-crack', 'sativa'),\n",
       " ('og-kush', 'hybrid'),\n",
       " ('granddaddy-purple', 'indica'),\n",
       " ('original-glue', 'hybrid'),\n",
       " ('white-widow', 'hybrid'),\n",
       " ('jack-herer', 'sativa'),\n",
       " ('bubba-kush', 'indica'),\n",
       " ('pineapple-express', 'hybrid'),\n",
       " ('trainwreck', 'hybrid'),\n",
       " ('ak-47', 'hybrid'),\n",
       " ('durban-poison', 'sativa'),\n",
       " ('northern-lights', 'indica'),\n",
       " ('headband', 'hybrid'),\n",
       " ('blue-cheese', 'indica'),\n",
       " ('strawberry-cough', 'sativa'),\n",
       " ('chemdawg', 'hybrid'),\n",
       " ('purple-kush', 'indica'),\n",
       " ('lemon-haze', 'sativa'),\n",
       " ('super-lemon-haze', 'sativa'),\n",
       " ('grape-ape', 'indica'),\n",
       " ('blueberry', 'indica'),\n",
       " ('alaskan-thunder-fuck', 'sativa'),\n",
       " ('super-silver-haze', 'sativa'),\n",
       " ('blackberry-kush', 'indica'),\n",
       " ('cherry-pie', 'hybrid'),\n",
       " ('master-kush', 'indica'),\n",
       " ('skywalker-og', 'hybrid'),\n",
       " ('cheese', 'hybrid'),\n",
       " ('death-star', 'indica'),\n",
       " ('chocolope', 'sativa'),\n",
       " ('amnesia-haze', 'sativa'),\n",
       " ('tahoe-og', 'hybrid'),\n",
       " ('maui-wowie', 'sativa'),\n",
       " ('platinum-gsc', 'hybrid'),\n",
       " ('harlequin', 'sativa'),\n",
       " ('gods-gift', 'indica'),\n",
       " ('la-confidential', 'indica'),\n",
       " ('agent-orange', 'hybrid'),\n",
       " ('purple-urkle', 'indica'),\n",
       " ('lemon-kush', 'hybrid'),\n",
       " ('mazar-x-blueberry', 'hybrid'),\n",
       " ('golden-goat', 'hybrid'),\n",
       " ('afghan-kush', 'indica'),\n",
       " ('dutch-treat', 'hybrid'),\n",
       " ('hindu-kush', 'indica')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Only needs to be ran once\\nd = scraper_dummy1(test_strains)'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#Only needs to be ran once\n",
    "d = scraper_dummy1(test_strains)\"\"\"\n",
    "\n",
    "#Already ran it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue-dream 874\n",
      "sour-diesel 1004\n",
      "gsc 560\n",
      "green-crack 486\n",
      "og-kush 394\n",
      "granddaddy-purple 534\n",
      "original-glue 454\n",
      "white-widow 286\n",
      "jack-herer 203\n",
      "bubba-kush 254\n",
      "pineapple-express 237\n",
      "trainwreck 40\n",
      "ak-47 188\n",
      "durban-poison 209\n",
      "northern-lights 179\n",
      "headband 140\n",
      "blue-cheese 115\n",
      "strawberry-cough 140\n",
      "chemdawg 140\n",
      "purple-kush 88\n",
      "lemon-haze 87\n",
      "super-lemon-haze 121\n",
      "grape-ape 156\n",
      "blueberry 111\n",
      "alaskan-thunder-fuck 96\n",
      "super-silver-haze 109\n",
      "blackberry-kush 92\n",
      "cherry-pie 125\n",
      "master-kush 69\n",
      "skywalker-og 30\n",
      "cheese 38\n",
      "death-star 85\n",
      "chocolope 55\n",
      "amnesia-haze 163\n",
      "tahoe-og 77\n",
      "maui-wowie 115\n",
      "platinum-gsc 74\n",
      "harlequin 175\n",
      "gods-gift 76\n",
      "la-confidential 90\n",
      "agent-orange 78\n",
      "purple-urkle 142\n",
      "lemon-kush 63\n",
      "mazar-x-blueberry 30\n",
      "golden-goat 71\n",
      "afghan-kush 52\n",
      "dutch-treat 37\n",
      "hindu-kush 56\n"
     ]
    }
   ],
   "source": [
    "for k in d.keys():\n",
    "    print(k,len(d[k]['user_rev']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': 'BenchAdventures',\n",
       " 'stars': 5.0,\n",
       " 'review': 'ive smoking recently dont need anything youre like youll want make sure floor clear tripping hazard laptop away water etcset snack start smoking make sure youre safe environmenthybrids generally put couch indica gsc make fine motor skill especially hard also especially de'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['gsc']['user_rev'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files(d):\n",
    "    cnt = 0\n",
    "    for strain in d.keys():\n",
    "\n",
    "        if not os.path.isdir(os.path.join(target_path, strain)):\n",
    "             os.mkdir(os.path.join(target_path, strain))\n",
    "\n",
    "        for rev in d[strain]['user_rev']:\n",
    "\n",
    "            with open(os.path.join(target_path, strain, strain+'{:05d}.txt'.format(cnt)), mode='w') as strain_file:\n",
    "                strain_file.write(rev['review'])\n",
    "\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_files(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ = \"a,able,about,across,after,all,almost,also,am,among,an,and,any,\\\n",
    "are,as,at,be,because,been,but,by,can,could,dear,did,do,does,either,\\\n",
    "else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,\\\n",
    "how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,\\\n",
    "me,might,most,must,my,neither,no,of,off,often,on,only,or,other,our,\\\n",
    "own,rather,said,say,says,she,should,since,so,some,than,that,the,their,\\\n",
    "them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,\\\n",
    "what,when,where,which,while,who,whom,why,will,with,would,yet,you,your]\".split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:301: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['your'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "    dataset = load_files(target_path, shuffle=False)\n",
    "    print('n_samples {}'.format(len(dataset.data)))\n",
    "\n",
    "    # split the dataset in training and test set:\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.15, random_state=None)\n",
    "\n",
    "    # TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "    # that are too rare or too frequent\n",
    "    clf = Pipeline([\n",
    "        ('vect',TfidfVectorizer(analyzer='character', stop_words=stopwords_)),\n",
    "        ('clf', Perceptron())\n",
    "    ])\n",
    "\n",
    "    # TfidfVectorizer().get_params()\n",
    "    # TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "    # more useful.\n",
    "    # Fit the pipeline on the training set using grid search for the parameters\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 5), (1,10),(1,20)],\n",
    "        'vect__analyzer': ['word']#,'char']\n",
    "    }\n",
    "    gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "    cclf = gs_clf.fit(docs_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vect__analyzer': 'word', 'vect__ngram_range': (1, 5)}\n",
      "0.5525925925925926\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "  .ipynb_checkpoints       0.00      0.00      0.00         0\n",
      "         afghan-kush       0.25      0.10      0.14        10\n",
      "        agent-orange       0.17      0.11      0.13         9\n",
      "               ak-47       0.47      0.26      0.33        31\n",
      "alaskan-thunder-fuck       0.22      0.17      0.19        12\n",
      "        amnesia-haze       0.46      0.22      0.30        27\n",
      "     blackberry-kush       0.00      0.00      0.00        11\n",
      "         blue-cheese       0.42      0.23      0.29        22\n",
      "          blue-dream       0.84      0.88      0.86       129\n",
      "           blueberry       0.33      0.14      0.20        14\n",
      "          bubba-kush       0.26      0.19      0.22        47\n",
      "              cheese       0.00      0.00      0.00         4\n",
      "            chemdawg       0.17      0.06      0.08        18\n",
      "          cherry-pie       0.47      0.54      0.50        13\n",
      "           chocolope       0.00      0.00      0.00         7\n",
      "          death-star       0.06      0.11      0.08         9\n",
      "       durban-poison       0.42      0.28      0.33        36\n",
      "         dutch-treat       0.33      0.29      0.31         7\n",
      "           gods-gift       0.11      0.30      0.16        10\n",
      "         golden-goat       0.05      0.12      0.07         8\n",
      "   granddaddy-purple       0.67      0.81      0.73        79\n",
      "           grape-ape       0.43      0.32      0.37        28\n",
      "         green-crack       0.83      0.86      0.84        79\n",
      "                 gsc       0.89      0.87      0.88        71\n",
      "           harlequin       0.41      0.55      0.47        31\n",
      "            headband       0.50      0.19      0.28        21\n",
      "          hindu-kush       0.00      0.00      0.00         9\n",
      "          jack-herer       0.39      0.26      0.31        35\n",
      "     la-confidential       0.38      0.20      0.26        15\n",
      "          lemon-haze       0.10      0.08      0.09        13\n",
      "          lemon-kush       0.44      0.29      0.35        14\n",
      "         master-kush       0.12      0.12      0.12         8\n",
      "          maui-wowie       0.50      0.29      0.37        17\n",
      "   mazar-x-blueberry       0.00      0.00      0.00         5\n",
      "     northern-lights       0.19      0.23      0.20        22\n",
      "             og-kush       0.77      0.96      0.86        56\n",
      "       original-glue       0.86      0.88      0.87        69\n",
      "   pineapple-express       0.42      0.31      0.36        32\n",
      "        platinum-gsc       0.33      0.08      0.13        12\n",
      "         purple-kush       0.38      0.30      0.33        10\n",
      "        purple-urkle       0.07      0.05      0.06        20\n",
      "        skywalker-og       0.00      0.00      0.00         5\n",
      "         sour-diesel       0.76      0.90      0.82       151\n",
      "    strawberry-cough       0.31      0.39      0.35        23\n",
      "    super-lemon-haze       0.27      0.14      0.19        21\n",
      "   super-silver-haze       0.57      0.22      0.32        18\n",
      "            tahoe-og       0.25      0.14      0.18        14\n",
      "          trainwreck       0.08      0.20      0.11         5\n",
      "         white-widow       0.82      0.86      0.84        43\n",
      "\n",
      "           micro avg       0.55      0.55      0.55      1350\n",
      "           macro avg       0.34      0.30      0.30      1350\n",
      "        weighted avg       0.56      0.55      0.55      1350\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanweil/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = gs_clf.predict(docs_test)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "print(cclf.score(docs_test, y_test))\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "#print(cm)\n",
    "\n",
    "plt.matshow(cm, cmap=plt.cm.cool)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To feel these like (yawn) try smoking purple-urkle\n",
      "To feel these like (smile) try smoking amnesia-haze\n",
      "To feel these like (happy) try smoking blue-dream\n",
      "To feel these like (fun) try smoking ak-47\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\n",
    "    u'yawn',\n",
    "    u'smile',\n",
    "    u'happy',\n",
    "    u'fun'\n",
    "]\n",
    "\n",
    "predicted = cclf.predict(test_strings)\n",
    "\n",
    "for s, p in zip(test_strings, predicted):\n",
    "    print(u'To feel these like ({}) try smoking {}'.format(s, dataset.target_names[p]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
