{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = pymongo.MongoClient()  # Connect to the MongoDB server using default settings\n",
    "db = mc['strain_reviews']  # Use (or create) a database called 'election_predictions'\n",
    "docs = db['review']  # Use (or create) a collection called 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.count_documents(filter={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is how i want the scrape to work\n",
    "\n",
    "    \"\"\"LOS = [List of Strains]\n",
    "        for s in LOS:\n",
    "        url = \"https://www.leafly.com/{}/reviews?page=\".format(s)\n",
    "        for i in range(1,100):\n",
    "            d = get_reviews(url+str(i))\n",
    "            st, rev = parse_docs(d)\n",
    "            if len(st) > 0:\n",
    "               append.(add to your dictionary)\n",
    "            else:\n",
    "                break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_check2(l):\n",
    "    \"\"\"This checks to see if a url is already in my database of reviews. \n",
    "    Only needs to be run in the get reviews function\"\"\"\n",
    "    for url in l:\n",
    "        if docs.find_one({'url':url}):\n",
    "            None\n",
    "        else:\n",
    "            docs.insert_one({'url': url,\n",
    "                 'html': requests.get(url).content\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews2(l):\n",
    "    \"\"\"Pass in a list of URL's and return them in a mongo db table as a dicitonary with \n",
    "    {'url', 'html'} and their corresponding values\"\"\"\n",
    "    r = requests.get(l)\n",
    "    html = (r.content)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars_list(d):\n",
    "    stars = []\n",
    "    for key, values in d.items():\n",
    "        soup = BeautifulSoup(values, 'html.parser')\n",
    "        tags = soup.select(\"div.div.stars\")\n",
    "        for t in tags:\n",
    "            stars.append(t.attrs['style'])\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_int_conv(l):\n",
    "    flat_stars= []\n",
    "    star_num = []\n",
    "    for s in l:\n",
    "        star = int((s[6:].split(';')[0]).strip('px'))\n",
    "        star_num.append((star/22))\n",
    "    return star_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_strains(i):\n",
    "    LOS = []\n",
    "    r = requests.get(i)\n",
    "    soup2 = BeautifulSoup(r.content, 'html.parser')\n",
    "    strains = soup2.find_all('a', class_=\"ga_Explore_Strain_Tile\")\n",
    "    for s in strains:\n",
    "         LOS.append(str(s.attrs['href'])[1:])\n",
    "    return LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs2(d):\n",
    "    \"\"\"Parse the HTML docs that we have stored in a dictionary, return as a list.\n",
    "    Also scrape and parse star rating for each review \"\"\"\n",
    "    strain_text= []\n",
    "    star_rate = []\n",
    "    user_name = []\n",
    "    soup = BeautifulSoup(d, 'html.parser')\n",
    "    revs = soup.find_all('p',class_='strain-review__text') \n",
    "    for r in revs:\n",
    "        strain_text.append(r.text)\n",
    "    tags = soup.select(\"div.div.stars\")\n",
    "    star = []\n",
    "    for t in tags:\n",
    "        star.append(t.attrs['style'])\n",
    "    star_rate.append(star_int_conv(star))\n",
    "    users = soup.find_all('div', class_='strain-review__title')\n",
    "    for u in users:\n",
    "        temp = u.find('h2')\n",
    "        user_name.append(temp.text)\n",
    "    return star_rate, strain_text, user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test works better, is updated!\n",
    "def scraper_dummy1(los):\n",
    "    los_urls = []\n",
    "    rev_urls = []\n",
    "    for s in los:\n",
    "        url = \"https://www.leafly.com{}/reviews?page=\".format(s)\n",
    "        print(url)\n",
    "        for i in range(1,100):\n",
    "            rev_urls=url+str(i)\n",
    "            d = get_reviews2(rev_urls)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            print(users)\n",
    "            if len(star[0]) == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy_test(los):\n",
    "    los_urls = []\n",
    "    rev_urls = []\n",
    "    user_list_of_lists = []\n",
    "    star_list_of_lists = []\n",
    "    reviews_list_o_lists = []\n",
    "    #grab URL landing pages for reviews on each strain.\n",
    "    for s in los:\n",
    "        url = \"https://www.leafly.com/{}/reviews?page=\".format(s)\n",
    "        strain_star_list = []\n",
    "        strain_user_list = []\n",
    "        strain_rev_list = []\n",
    "        #get all reviews, stars, and users for each strain in list of strains\n",
    "        for i in range(1,100):\n",
    "            rev_urls=url+str(i)\n",
    "            d = get_reviews2(rev_urls)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            #return stars, strains, reviews, in one list, not list of lists for each page scraped. \n",
    "            #star_unlisted = \n",
    "            strain_star_list.extend([x for x in star[0]])\n",
    "            strain_user_list.extend(users)\n",
    "            strain_rev_list.extend(reviews)\n",
    "            if len(star[0]) == 0:\n",
    "                break\n",
    "        #these are long single lists, not list of lists\n",
    "        star_list_of_lists.append(strain_star_list)\n",
    "        user_list_of_lists.append(strain_user_list)\n",
    "        reviews_list_o_lists.append(strain_rev_list)\n",
    "        #make into dictionaries \n",
    "        for s in los:\n",
    "            star_ds = []\n",
    "            rev_ds = []\n",
    "            for i in range(len(star_list_of_lists)):\n",
    "                user_revs =  dict(list(zip(user_list_of_lists[i], reviews_list_o_lists[i])))\n",
    "                rev_ds.append(user_revs)\n",
    "                user_stars = dict(list(zip(user_list_of_lists[i], star_list_of_lists[i])))\n",
    "                star_ds.append(user_stars)\n",
    "    #create Pandas DF of each dictionary as well.\n",
    "    star_dfs = []\n",
    "    rev_dfs = []\n",
    "    for s in star_ds:\n",
    "        star_dfs.append(pd.DataFrame.from_dict(s, orient='index')) \n",
    "    for r in rev_ds: \n",
    "        rev_dfs.append(pd.DataFrame.from_dict(r, orient ='index'))\n",
    "    #create large dataframe\n",
    "    star_df = pd.concat(star_dfs, axis=1, sort=True)\n",
    "    rev_df = pd.concat(rev_dfs, axis=1, sort=True)\n",
    "    rev_df.columns = los\n",
    "    star_df.columns = los\n",
    "    return star_df, rev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strains = list_o_strains('https://www.leafly.com/explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hybrid/original-glue'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strains[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars, reviews = scraper_dummy_test(test_strains[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hybrid/original-glue</th>\n",
       "      <th>hybrid/white-widow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13Gawd</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152gjeng</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1taste</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206SEA</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419plus1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420life</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420reyes420</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561.welly</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8CoreXeon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8characters</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALIENCHIC</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaro</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abigantimos</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abvchef</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anonbrra</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AntonioCoolio</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArthritisPain</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ayestriff</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BadBehavior89</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Badgerboy</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bailey2427</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BakinKush</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaronOfBud</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bartndk</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigPapa617</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BobCantwell</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bobbilynn</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brian420pm</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Budsey420</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smokeyonekenobi</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somacolorado</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spkout2005</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srubek</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stoney-yo</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stormyknight3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>synthara</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tank7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tdogg241</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tevin420s</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thcguruv</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thejuju</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tinfoil</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tlarchitect</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmaass4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trapxoxo</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troy1ne</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>upcomingwhisper</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanillachigchampa</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanugrah</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vicu12</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vito.genovese.7568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warriorforbeauty</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weeddude1234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whitewidow81</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>willir97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witchfinder</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xPatrick_BatemanX</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xSarahcate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xpattycakes</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    hybrid/original-glue  hybrid/white-widow\n",
       "13Gawd                               5.0                 NaN\n",
       "152gjeng                             NaN                 3.0\n",
       "1taste                               NaN                 3.0\n",
       "206SEA                               5.0                 NaN\n",
       "419plus1                             NaN                 4.0\n",
       "420life                              5.0                 NaN\n",
       "420reyes420                          5.0                 NaN\n",
       "561.welly                            5.0                 NaN\n",
       "8CoreXeon                            NaN                 4.0\n",
       "8characters                          5.0                 NaN\n",
       "ALIENCHIC                            5.0                 NaN\n",
       "Aaro                                 NaN                 4.0\n",
       "Abigantimos                          5.0                 NaN\n",
       "Abvchef                              4.0                 NaN\n",
       "Anonbrra                             NaN                 5.0\n",
       "AntonioCoolio                        4.0                 NaN\n",
       "Apil                                 NaN                 5.0\n",
       "ArthritisPain                        NaN                 3.0\n",
       "Ayestriff                            4.0                 NaN\n",
       "BadBehavior89                        NaN                 5.0\n",
       "Badgerboy                            5.0                 NaN\n",
       "Bailey2427                           5.0                 NaN\n",
       "BakinKush                            NaN                 5.0\n",
       "BaronOfBud                           5.0                 NaN\n",
       "Bartndk                              NaN                 5.0\n",
       "BigPapa617                           5.0                 NaN\n",
       "BobCantwell                          NaN                 5.0\n",
       "Bobbilynn                            5.0                 NaN\n",
       "Brian420pm                           5.0                 NaN\n",
       "Budsey420                            5.0                 NaN\n",
       "...                                  ...                 ...\n",
       "smokeyonekenobi                      5.0                 NaN\n",
       "somacolorado                         NaN                 5.0\n",
       "spkout2005                           3.0                 3.0\n",
       "srubek                               NaN                 4.0\n",
       "stoney-yo                            5.0                 NaN\n",
       "stormyknight3                        3.0                 NaN\n",
       "synthara                             3.0                 NaN\n",
       "tank7                                NaN                 5.0\n",
       "tdogg241                             5.0                 NaN\n",
       "tevin420s                            2.0                 NaN\n",
       "thcguruv                             NaN                 5.0\n",
       "thejuju                              4.0                 NaN\n",
       "tinfoil                              5.0                 NaN\n",
       "tlarchitect                          4.0                 NaN\n",
       "tmaass4                              5.0                 NaN\n",
       "trapxoxo                             5.0                 NaN\n",
       "troy1ne                              5.0                 NaN\n",
       "upcomingwhisper                      NaN                 5.0\n",
       "vanillachigchampa                    4.0                 NaN\n",
       "vanugrah                             5.0                 NaN\n",
       "vicu12                               4.0                 NaN\n",
       "vito.genovese.7568                   NaN                 4.0\n",
       "warriorforbeauty                     5.0                 NaN\n",
       "weeddude1234                         NaN                 4.0\n",
       "whitewidow81                         NaN                 4.0\n",
       "willir97                             NaN                 5.0\n",
       "witchfinder                          5.0                 NaN\n",
       "xPatrick_BatemanX                    NaN                 3.0\n",
       "xSarahcate                           NaN                 4.0\n",
       "xpattycakes                          NaN                 5.0\n",
       "\n",
       "[349 rows x 2 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
