{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = pymongo.MongoClient()  # Connect to the MongoDB server using default settings\n",
    "db = mc['strain_reviews']  # Use (or create) a database called 'election_predictions'\n",
    "docs = db['review']  # Use (or create) a collection called 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.count_documents(filter={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is how i want the scrape to work\n",
    "\n",
    "    \"\"\"LOS = [List of Strains]\n",
    "        for s in LOS:\n",
    "        url = \"https://www.leafly.com/{}/reviews?page=\".format(s)\n",
    "        for i in range(1,100):\n",
    "            d = get_reviews(url+str(i))\n",
    "            st, rev = parse_docs(d)\n",
    "            if len(st) > 0:\n",
    "               append.(add to your dictionary)\n",
    "            else:\n",
    "                break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_check2(l):\n",
    "    \"\"\"This checks to see if a url is already in my database of reviews. \n",
    "    Only needs to be run in the get reviews function\"\"\"\n",
    "    for url in l:\n",
    "        if docs.find_one({'url':url}):\n",
    "            None\n",
    "        else:\n",
    "            docs.insert_one({'url': url,\n",
    "                 'html': requests.get(url).content\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews2(l):\n",
    "    \"\"\"Pass in a list of URL's and return them in a mongo db table as a dicitonary with \n",
    "    {'url', 'html'} and their corresponding values\"\"\"\n",
    "    r = requests.get(l)\n",
    "    html = (r.content)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars_list(d):\n",
    "    stars = []\n",
    "    for key, values in d.items():\n",
    "        soup = BeautifulSoup(values, 'html.parser')\n",
    "        tags = soup.select(\"div.div.stars\")\n",
    "        for t in tags:\n",
    "            stars.append(t.attrs['style'])\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_int_conv(l):\n",
    "    flat_stars= []\n",
    "    star_num = []\n",
    "    for s in l:\n",
    "        star = int((s[6:].split(';')[0]).strip('px'))\n",
    "        star_num.append((star/22))\n",
    "    return star_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_strains(i):\n",
    "    LOS = []\n",
    "    r = requests.get(i)\n",
    "    soup2 = BeautifulSoup(r.content, 'html.parser')\n",
    "    strains = soup2.find_all('a', class_=\"ga_Explore_Strain_Tile\")\n",
    "    for s in strains:\n",
    "        LOS.append(s.attrs['href'])\n",
    "    return LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs2(d):\n",
    "    \"\"\"Parse the HTML docs that we have stored in a dictionary, return as a list.\n",
    "    Also scrape and parse star rating for each review \"\"\"\n",
    "    strain_text= []\n",
    "    star_rate = []\n",
    "    user_name = []\n",
    "    soup = BeautifulSoup(d, 'html.parser')\n",
    "    revs = soup.find_all('p',class_='strain-review__text') \n",
    "    for r in revs:\n",
    "        strain_text.append(r.text)\n",
    "    tags = soup.select(\"div.div.stars\")\n",
    "    star = []\n",
    "    for t in tags:\n",
    "        star.append(t.attrs['style'])\n",
    "    star_rate.append(star_int_conv(star))\n",
    "    users = soup.find_all('div', class_='strain-review__title')\n",
    "    for u in users:\n",
    "        temp = u.find('h2')\n",
    "        user_name.append(temp.text)\n",
    "    return star_rate, strain_text  #, user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy(los):\n",
    "    los_urls = []\n",
    "    rev_urls = []\n",
    "    for s in los:\n",
    "        url = \"https://www.leafly.com{}/reviews?page=\".format(s)\n",
    "        print(url)\n",
    "        for i in range(1,100):\n",
    "            rev_urls=url+str(i)\n",
    "            d = get_reviews2(rev_urls)\n",
    "            star, reviews = parse_docs2(d)\n",
    "            print(star)\n",
    "            if len(star[0]) == 0:\n",
    "                break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strains = list_o_strains('https://www.leafly.com/explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hybrid/original-glue'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strains[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.leafly.com/hybrid/original-glue/reviews?page=\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 2.0]]\n",
      "[[5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 2.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0]]\n",
      "[[5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0]]\n",
      "[[3.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0]]\n",
      "[[3.0, 5.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[4.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 2.0, 4.0]]\n",
      "[[5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 4.0]]\n",
      "[[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0]]\n",
      "[[3.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0]]\n",
      "[[4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0]]\n",
      "[[5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0]]\n",
      "[[5.0, 4.0, 3.0, 5.0, 5.0, 5.0, 4.0, 5.0]]\n",
      "[[4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0]]\n",
      "[[5.0, 5.0, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[4.0]]\n",
      "[[]]\n",
      "https://www.leafly.com/hybrid/white-widow/reviews?page=\n",
      "[[4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0]]\n",
      "[[5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0]]\n",
      "[[5.0, 4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0]]\n",
      "[[5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[4.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0]]\n",
      "[[3.0, 5.0, 5.0, 5.0, 3.0, 5.0, 3.0, 5.0]]\n",
      "[[4.0, 5.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0]]\n",
      "[[4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 5.0]]\n",
      "[[4.0, 4.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0]]\n",
      "[[3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[5.0, 4.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
      "[[3.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0]]\n",
      "[[5.0, 5.0, 3.0, 5.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[4.0, 5.0, 5.0, 3.0, 5.0, 5.0, 5.0, 4.0]]\n",
      "[[5.0, 5.0, 5.0, 4.0, 5.0]]\n",
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "scraper_dummy(test_strains[6:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
