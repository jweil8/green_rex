{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = pymongo.MongoClient()  # Connect to the MongoDB server using default settings\n",
    "db = mc['strain_reviews']  # Use (or create) a database called 'election_predictions'\n",
    "docs = db['review']  # Use (or create) a collection called 'docs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.count_documents(filter={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is how i want the scrape to work\n",
    "\n",
    "    \"\"\"LOS = [List of Strains]\n",
    "        for s in LOS:\n",
    "        url = \"https://www.leafly.com/{}/reviews?page=\".format(s)\n",
    "        for i in range(1,100):\n",
    "            d = get_reviews(url+str(i))\n",
    "            st, rev = parse_docs(d)\n",
    "            if len(st) > 0:\n",
    "               append.(add to your dictionary)\n",
    "            else:\n",
    "                break\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_check2(l):\n",
    "    \"\"\"This checks to see if a url is already in my database of reviews. \n",
    "    Only needs to be run in the get reviews function\"\"\"\n",
    "    for url in l:\n",
    "        if docs.find_one({'url':url}):\n",
    "            None\n",
    "        else:\n",
    "            docs.insert_one({'url': url,\n",
    "                 'html': requests.get(url).content\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews2(l):\n",
    "    \"\"\"Pass in a list of URL's and return them in a mongo db table as a dicitonary with \n",
    "    {'url', 'html'} and their corresponding values\"\"\"\n",
    "    r = requests.get(l)\n",
    "    html = (r.content)\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stars_list(d):\n",
    "    stars = []\n",
    "    for key, values in d.items():\n",
    "        soup = BeautifulSoup(values, 'html.parser')\n",
    "        tags = soup.select(\"div.div.stars\")\n",
    "        for t in tags:\n",
    "            stars.append(t.attrs['style'])\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_int_conv(l):\n",
    "    flat_stars= []\n",
    "    star_num = []\n",
    "    for s in l:\n",
    "        star = int((s[6:].split(';')[0]).strip('px'))\n",
    "        star_num.append((star/22))\n",
    "    return star_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_o_strains(i):\n",
    "    LOS = []\n",
    "    r = requests.get(i)\n",
    "    soup2 = BeautifulSoup(r.content, 'html.parser')\n",
    "    strains = soup2.find_all('a', class_=\"ga_Explore_Strain_Tile\")\n",
    "    for s in strains:\n",
    "        LOS.append(s.attrs['href'])\n",
    "    return LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docs2(d):\n",
    "    \"\"\"Parse the HTML docs that we have stored in a dictionary, return as a list.\n",
    "    Also scrape and parse star rating for each review \"\"\"\n",
    "    strain_text= []\n",
    "    star_rate = []\n",
    "    user_name = []\n",
    "    soup = BeautifulSoup(d, 'html.parser')\n",
    "    revs = soup.find_all('p',class_='strain-review__text') \n",
    "    for r in revs:\n",
    "        strain_text.append(r.text)\n",
    "    tags = soup.select(\"div.div.stars\")\n",
    "    star = []\n",
    "    for t in tags:\n",
    "        star.append(t.attrs['style'])\n",
    "    star_rate.append(star_int_conv(star))\n",
    "    users = soup.find_all('div', class_='strain-review__title')\n",
    "    for u in users:\n",
    "        temp = u.find('h2')\n",
    "        user_name.append(temp.text)\n",
    "    return star_rate, strain_text, user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy(los):\n",
    "    los_urls = []\n",
    "    rev_urls = []\n",
    "    for s in los:\n",
    "        url = \"https://www.leafly.com{}/reviews?page=\".format(s)\n",
    "        print(url)\n",
    "        for i in range(1,100):\n",
    "            rev_urls=url+str(i)\n",
    "            d = get_reviews2(rev_urls)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            print(users)\n",
    "            if len(star[0]) == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper_dummy_test(los):\n",
    "    los_urls = []\n",
    "    rev_urls = []\n",
    "    user_list_of_lists = []\n",
    "    star_list_of_lists = []\n",
    "    reviews_list_of_lists = []\n",
    "    for s in los:\n",
    "        url = \"https://www.leafly.com{}/reviews?page=\".format(s)\n",
    "        print(url)\n",
    "        strain_star_list = []\n",
    "        strain_user_list = []\n",
    "        for i in range(1,100):\n",
    "            rev_urls=url+str(i)\n",
    "            d = get_reviews2(rev_urls)\n",
    "            star, reviews, users = parse_docs2(d)\n",
    "            star_unlisted = [x for x in star[0]]\n",
    "            strain_star_list.extend(star_unlisted)\n",
    "            user_unlisted = [x for x in users[0]]\n",
    "            strain_user_list.extend(user_unlisted)\n",
    "#             print(star)\n",
    "            if len(star[0]) == 0:\n",
    "                break\n",
    "        star_list_of_lists.append(strain_star_list)\n",
    "        \n",
    "    return  users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strains = list_o_strains('https://www.leafly.com/explore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hybrid/original-glue'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strains[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.leafly.com/hybrid/original-glue/reviews?page=\n",
      "['chronicallymedicated', 'MZ_PHD_in_420', 'gatorhunts420', 'calebargh', 'purpleurklealienchempantsdogkush', 'chroniccannabisconsumsr', 'mrobadamus', 'Budsey420']\n",
      "['Munchiez2', 'chroniccannabisconsumsr', 'ChronicComic', 'Greenleaf_Compton', 'Hookakat1', 'ourlife', 'LegitLogic', 'JustinCider']\n",
      "['flowerbud420', 'jpersch', 'KindGoddess420', 'OnePDXOne', 'sirflingspoo', '420life', 'Free2beme', 'Donnie1967']\n",
      "['Ogflight2space', 'warriorforbeauty', 'chrisg3121', 'thejuju', 'Sammi_S', 'redasalobster', 'tmaass4', 'DankNunuFresh']\n",
      "['EssTee5ive', 'PipeDreamer4', 'quentello', 'vanugrah', 'PumpkinGemini11', 'tinfoil', 'funkmasterastronaut', 'BaronOfBud']\n",
      "['TheWidowsSon226', 'GooglyDancingBear', 'Stu35846', 'SalmonCreekBigBuds', 'plschoosenewusername', 'LegitLogic', 'nevildog', 'MGomsrud']\n",
      "['cogollohazer', 'RWright', 'bge1342', 'bosieboy', 'dbvapor', 'guy7', 'vanillachigchampa', 'Ayestriff']\n",
      "['njhybrid', '420reyes420', 'KittyD2', 'CannabisExpert', 'Brian420pm', 'Monaliza', 'BigPapa617', 'Abvchef']\n",
      "['hughlaurie', 'melisa12g', 'frostednuggets', 'DREDAY81', 'Cryrste', 'Kyky98', 'RealTimeReview', 'Bobbilynn']\n",
      "['Stewster', 'MyJokerHandStayLIT', 'lordrak', 'Sloppysundance', 'ChimeraLDM', 'Zamorman', 'SassyStonerSisters', 'STRAINBRAIN769']\n",
      "['Milkman_rs', 'Rockplant', 'MagicLady', 'highenuff', 'lta2rl', 'monique79', 'MoTokez', 'trapxoxo']\n",
      "['palmermoma', 'troy1ne', 'Skipstorm', 'LivLace', 'Imathugimadiehigh', 'priestt', 'TheExorcist', 'babbalooeybooey']\n",
      "['Oldtimefacemelt', 'Eternal.H', 'Clapback24', 'Pandora12m', 'matt842', 'tlarchitect', 'Dreathedragonslayah', 'GoodVibes79']\n",
      "['Richlovespot', 'Lbiggz', 'smokeyonekenobi', 'Coco.Chronic', 'witchfinder', 'northeastreaper', 'Sialovesweed', 'Revoures']\n",
      "['SportbikeDoc', 'jm1214', 'fangychan', 'stormyknight3', 'PrincessProse', 'seanzy84', 'lollipops', 'VidyaGames']\n",
      "['Verkat', 'Nicholemariedonovan', 'Servingkush', 'VriskaQ', 'pitbull420303', 'Abigantimos', 'TreeGuyy', 'Bailey2427']\n",
      "['Rjthegeek420', 'bleyzer', 'JDog66', 'MentalNote', 'TrapstarCZ', 'mmmonicapb', 'vicu12', 'tevin420s']\n",
      "['Maryfaith88', 'Weed420map', 'MrsRachBall13', 'alanalalurie', 'MadameGreen3988', 'Geee35', 'JorundHallthor', 'Romelo50Cal']\n",
      "['bamf', 'GLstoner', 'Mbreezythunder', 'skot1420', 'Thekingofweed24', '206SEA', 'Skyhigh01', 'sheraealford']\n",
      "['tdogg241', 'spkout2005', 'PsychosisGuy', 'Jblick', 'greenscreenmx', 'onehitterharry', 'Okiesfinest', 'Sunni215']\n",
      "['Jb0317', '8characters', 'kashdino', '561.welly', 'Mokentoke420', 'EBONI_GODDESS', 'hagoshipeo', 'MaineMedicalGuy']\n",
      "['CapeLadyTokes', 'FutchAndCalli', 'DildoShwaggins420', 'stoney-yo', '13Gawd', 'MaryJanezWife', 'koiboi', 'MoBudFore']\n",
      "['DEAAgent13', 'Hb33', 'KRAZYxRAZOR', 'nooxb', 'Rojachick', 'SmokingEveryday', 'Badgerboy', 'Dr.Coinpurse']\n",
      "['krankkinder', 'ShatterLutter', 'GunnyOG', 'derwinaco', 'Unsound_fox', 'lguttillo', 'LotusKai', 'Nazgul420']\n",
      "['Workoutsense', 'Dbergmann35', 'GeorgeHarris731', 'dieseldamsel', 'jcrowley420', 'PEPPERKID420', 'DeepfriedSooner', 'Lizzymay2901']\n",
      "['FishStoneMan', 'mustard_sauce', 'DrReggieDro', 'Skunk76', 'TC3888', 'AntonioCoolio', 'fivesmokesfour', 'Joeldubs']\n",
      "['synthara', 'jpsr69', 'Hsines1', 'kooshkween', 'Harrypothead87', 'shrathor', 'ALIENCHIC', 'Hbw007']\n",
      "['Gchris11', 'dabanales64']\n",
      "[]\n",
      "https://www.leafly.com/hybrid/white-widow/reviews?page=\n",
      "['hi2', 'MurderMyLove', 'JJMaxwell', 'greeneyeganja.girl', 'GreenPie', 'Ramoburo', 'kantheist', 'iamcherryface']\n",
      "['GanjaGoddess410', 'ChemicalHazex', 'BobCantwell', 'BadBehavior89', 'KindGodess420', 'willir97', 'somacolorado', 'CanadaKush']\n",
      "['John18', 'Pikarya', 'TSmoove', 'whitewidow81', 'allnaturalfitness', 'Flakzter', 'xSarahcate', 'StonerStig']\n",
      "['bobross559', 'srubek', 'KindGodess420', 'ImaFlyboy', 'ArthritisPain', 'Lumo', 'Reighly', 'BakinKush']\n",
      "['laj821', 'hurdyhurdy', 'Dryland2012', 'highmonkey', 'kalamardesk', 'StonedHousewife', 'HudsonCole', 'RavenBanes']\n",
      "['Kayley14', 'cmgunder', 'Spanish420', 'bdriskell99', 'DiscordedDiscord', 'inthewild', 'Deevaa', 'vito.genovese.7568']\n",
      "['Aaro', 'artyfartyblah', 'googleymoo', 'weeddude1234', 'Velocity666', 'LemonKatt', 'CANNIBALCORPSE666', 'Anonbrra']\n",
      "['Trinli66', 'Paperplaneprincess09', 'MrsRachBall13', 'LsdInMyWee', 'Apil', 'blommen', 'tank7', 'Sloppysundance']\n",
      "['1taste', 'drealii', 'Bartndk', 'blackcoffeekush', 'JuJumanski', 'TeamScienceOttawa', 'Harrypothead87', 'Tones06']\n",
      "['Flutterby-420', 'mlindsey886', 'Coyboy81', '152gjeng', 'Supa21High', 'Ladybug720', 'ColtyZoltog', 'Rtimd2']\n",
      "['bostondrinks', 'MalteBlume420', 'Ediks420', 'KaneKush13', 'LindonTheJoker', 'claggy', 'XxdahmerxX', 'freeasabird8317']\n",
      "['Okiechokie', 'MinhyukJ', 'GentlemanToker', 'RayG74', 'brittanyx4628', 'InTheMorning', 'TakenHoodie420', 'JeppeJeppe']\n",
      "['xPatrick_BatemanX', 'IrieBwoy1', 'ForbiddenFlowers', 'thcguruv', 'Dadplaid', 'Serpentethyx', 'xpattycakes', 'littlerivers']\n",
      "['Skyhigh01', 'Rob420pimp', 'spkout2005', 'sammimb0', 'GreenSpirited', 'CalvinjwHuggins', 'upcomingwhisper', 'arkansasboy420']\n",
      "['Danmilan11', 'KWGriff', 'parksdestroy', 'carl.mart', 'serious_russian', 'matt842', 'Oliviaroxhard', 'MsBhavn07']\n",
      "['VeeWeezie', 'Marilize', 'EBONI_GODDESS', 'FinnDoering', 'becks89', 'nathan.felix', 'Nuggetlover420', 'rambler99']\n",
      "['8CoreXeon', 'GanjaMasta10', 'TebowtheFIST56', 'omni239', 'PaoloJ8', 'Evenan', 'lotega', 'SirSparky']\n",
      "['Gonatural1980', 'Sweetchildofmine', 'jemitts', '419plus1', 'SeanDuffyII']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "test = scraper_dummy(test_strains[6:8])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0]]\n",
    "b = [[5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 5.0, 5.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in b[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-7901216d4d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "i = len(a)\n",
    "[x for x in a[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
