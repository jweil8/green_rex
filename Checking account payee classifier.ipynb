{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "source_path = 'datasets'\n",
    "source_file = '2017 Actuals.csv'\n",
    "target_path = 'payees'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load payee data in directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open(os.path.join(source_path,source_file), mode='r') as csvfile:\n",
    "#     reader = csv.reader(csvfile, delimiter=',')\n",
    "#     cnt = 0\n",
    "    \n",
    "#     for row in reader:\n",
    "#         if first:\n",
    "#             first = False\n",
    "#             continue\n",
    "        \n",
    "#         outdir = row[1]\n",
    "#         if not os.path.isdir(os.path.join(target_path,outdir)):\n",
    "#             os.mkdir(os.path.join(target_path,outdir))\n",
    "            \n",
    "#         with open(os.path.join(target_path,outdir,'payee{:04d}.txt'.format(cnt)), mode='w') as payee_file:\n",
    "#             payee_file.write(row[0])\n",
    "            \n",
    "#         cnt += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify payee data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples 1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "    dataset = load_files(target_path, shuffle=False)\n",
    "    print('n_samples {}'.format(len(dataset.data)))\n",
    "\n",
    "    # split the dataset in training and test set:\n",
    "    docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "        dataset.data, dataset.target, test_size=0.25, random_state=None)\n",
    "\n",
    "    # TASK: Build a vectorizer / classifier pipeline that filters out tokens\n",
    "    # that are too rare or too frequent\n",
    "    clf = Pipeline([\n",
    "        ('vect',TfidfVectorizer(analyzer='character')),\n",
    "        ('clf', Perceptron())\n",
    "    ])\n",
    "\n",
    "    # TfidfVectorizer().get_params()\n",
    "    # TASK: Build a grid search to find out whether unigrams or bigrams are\n",
    "    # more useful.\n",
    "    # Fit the pipeline on the training set using grid search for the parameters\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 3), (1,5)],\n",
    "        'vect__analyzer': ['char','word']\n",
    "    }\n",
    "    gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "    cclf = gs_clf.fit(docs_train, y_train)\n",
    "\n",
    "# TASK: Fit the pipeline on the training set\n",
    "#clf.fit(docs_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vect__analyzer': 'char', 'vect__ngram_range': (1, 5)}\n",
      "0.900900900901\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "            Auto       0.94      0.70      0.80        23\n",
      "        Business       0.57      1.00      0.73         4\n",
      "            Cash       0.17      1.00      0.29         1\n",
      "         Charity       0.89      0.94      0.91        17\n",
      "        Clothing       0.83      0.45      0.59        11\n",
      "        Computer       1.00      0.50      0.67         2\n",
      "          Dining       0.90      0.97      0.93       117\n",
      "   Entertainment       1.00      0.69      0.82        13\n",
      "           Fixed       0.91      1.00      0.95        21\n",
      "           Gifts       0.00      0.00      0.00         1\n",
      "       Groceries       0.97      1.00      0.99       103\n",
      "       Household       0.91      0.74      0.82        39\n",
      "       Kid Stuff       1.00      0.86      0.92         7\n",
      "         Medical       0.60      0.75      0.67         8\n",
      "           Music       1.00      1.00      1.00        28\n",
      "  Personal Items       1.00      1.00      1.00         1\n",
      "Personal Service       0.75      1.00      0.86         6\n",
      "         Savings       0.00      0.00      0.00         0\n",
      "          Travel       0.87      0.81      0.84        16\n",
      "            Work       0.00      0.00      0.00         2\n",
      "           zzzzz       1.00      0.92      0.96        24\n",
      "\n",
      "     avg / total       0.92      0.90      0.90       444\n",
      "\n",
      "[[ 16   0   3   0   0   0   1   0   0   0   0   0   0   1   0   0   2   0\n",
      "    0   0   0]\n",
      " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   1   0  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   1   0   0   5   0   2   0   2   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   1   0 113   0   0   0   0   0   0   0   0   0   0   2\n",
      "    1   0   0]\n",
      " [  0   1   0   2   0   0   1   9   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  21   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 103   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  1   0   1   0   0   0   3   0   0   0   2  29   0   3   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   6   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0   6   0   0   0   0\n",
      "    1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  28   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "   13   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   1   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      "    0   0  22]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAASgQAgEQgA0v8A1lrNcaAyEl8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a179d2358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TASK: Predict the outcome on the testing set in a variable named y_predicted\n",
    "y_predicted = gs_clf.predict(docs_test)\n",
    "\n",
    "print(gs_clf.best_params_)\n",
    "print(cclf.score(docs_test, y_test))\n",
    "\n",
    "# Print the classification report\n",
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=dataset.target_names))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "print(cm)\n",
    "\n",
    "plt.matshow(cm, cmap=plt.cm.cool)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class of McDonalds is Dining\n",
      "The class of PotBelly is Dining\n",
      "The class of Similan is Dining\n",
      "The class of Water is Fixed\n"
     ]
    }
   ],
   "source": [
    "# Predict the result on some short new sentences:\n",
    "test_payees = [\n",
    "    u'McDonalds',\n",
    "    u'PotBelly',\n",
    "    u'Similan',\n",
    "    u'Water',\n",
    "]\n",
    "predicted = clf.predict(test_payees)\n",
    "\n",
    "for s, p in zip(test_payees, predicted):\n",
    "    print(u'The class of {} is {}'.format(s, dataset.target_names[p]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank = {\n",
    "    'chase': '/Users/jasonweil/Downloads/Chase3686_Activity_20180728.CSV',\n",
    "    'alaska' : '/Users/jasonweil/Documents/Financials/Budgets/Alaska 2018 H1.csv',\n",
    "    'citi': '/Users/jasonweil/Documents/Financials/Budgets/Citi 2018 H1.csv'\n",
    "}\n",
    "workdir = '/Users/jasonweil/Documents/Financials/Budgets/'#'/Users/jasonweil/Downloads'\n",
    "work_csv = 'Alaska 2018 H1.csv'#'Chase3686_Activity_20180728.CSV'\n",
    "first = True\n",
    "\n",
    "transactions = pd.read_csv(bank['citi'],index_col=False)\n",
    "payees = transactions['Description']\n",
    "        \n",
    "transactions['Class'] = [dataset.target_names[x] for x in gs_clf.predict(payees)]\n",
    "transactions.to_csv('/Users/jasonweil/Documents/Financials/Budgets/Citi classified 2018 H1.csv')\n",
    "# display(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Auto</th>\n",
       "      <td>-357.938333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business</th>\n",
       "      <td>-58.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cash</th>\n",
       "      <td>-158.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charity</th>\n",
       "      <td>-257.338333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothing</th>\n",
       "      <td>-402.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer</th>\n",
       "      <td>-7.736667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dining</th>\n",
       "      <td>-739.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment</th>\n",
       "      <td>-266.063333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fixed</th>\n",
       "      <td>-3250.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gifts</th>\n",
       "      <td>-18.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Groceries</th>\n",
       "      <td>-840.871667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household</th>\n",
       "      <td>-740.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kid Stuff</th>\n",
       "      <td>-430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medical</th>\n",
       "      <td>-430.306667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music</th>\n",
       "      <td>-68.271667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Items</th>\n",
       "      <td>-67.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Personal Service</th>\n",
       "      <td>-640.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Savings</th>\n",
       "      <td>-975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>-2498.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work</th>\n",
       "      <td>-5.863333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzzz</th>\n",
       "      <td>9192.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Amount\n",
       "Class                        \n",
       "Auto              -357.938333\n",
       "Business           -58.590000\n",
       "Cash              -158.791667\n",
       "Charity           -257.338333\n",
       "Clothing          -402.830000\n",
       "Computer            -7.736667\n",
       "Dining            -739.878333\n",
       "Entertainment     -266.063333\n",
       "Fixed            -3250.858333\n",
       "Gifts              -18.800000\n",
       "Groceries         -840.871667\n",
       "Household         -740.075000\n",
       "Kid Stuff         -430.000000\n",
       "Medical           -430.306667\n",
       "Music              -68.271667\n",
       "Personal Items     -67.908333\n",
       "Personal Service  -640.775000\n",
       "Savings           -975.000000\n",
       "Travel           -2498.330000\n",
       "Work                -5.863333\n",
       "zzzzz             9192.541667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv('/Users/jasonweil/Documents/Financials/Budgets/2018 H1.csv',index_col=False)\n",
    "transactions.groupby('Class')['Amount'].sum()/6\n",
    "transactions.groupby('Class').agg({'Amount':sum})/6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
